{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bickUGZABmwG",
        "outputId": "d323a97d-5447-464e-f9ec-afb8d3a52fce"
      },
      "outputs": [],
      "source": [
        "# !apt update\n",
        "# !apt install chromium-chromedriver\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "NQog9VBWDM3u"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from selenium.webdriver.common.by import By\n",
        "import logging\n",
        "import pandas as pd\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "import random\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "# options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "wd = webdriver.Chrome(options=options)\n",
        "actions = ActionChains(wd)\n",
        "\n",
        "wd.maximize_window()\n",
        "# wd.minimize_window()\n",
        "# wd.maximize_window()\n",
        "wd.switch_to.window(wd.current_window_handle)\n",
        "wd.implicitly_wait(10)\n",
        "\n",
        "wd.get('https://www.linkedin.com/')\n",
        "\n",
        "wd.implicitly_wait(10)\n",
        "\n",
        "# wd.get_screenshot_as_file('screenshot.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "9hSMmaAk-0q5"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "s1d3SWWJ-YXm"
      },
      "outputs": [],
      "source": [
        "# file_path = '/content/drive/My Drive/LinkedIn_Scrape/config.json'\n",
        "\n",
        "# Read the JSON file\n",
        "# with open(file_path, 'r') as config_file:\n",
        "#     config_data = json.load(config_file)\n",
        "\n",
        "# username = config_data.get('linkedin_username')\n",
        "username = \"huoerxiu@gmail.com\"\n",
        "password = \"PURDUEcs\"\n",
        "# password = config_data.get('linkedin_password')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "soet7vXEV3hf"
      },
      "outputs": [],
      "source": [
        "def login(user_name, password):\n",
        "  # user_name = input(\"Please enter your LinkedIn Username: \")\n",
        "  # password = getpass.getpass('Please enter your LinkedIn Password: ')\n",
        "  wd.find_element(By.XPATH, '//*[@id=\"session_key\"]').send_keys(user_name)\n",
        "  wd.implicitly_wait(10)\n",
        "  wd.find_element(By.XPATH,'//*[@id=\"session_password\"]').send_keys(password)\n",
        "  wd.implicitly_wait(5)\n",
        "\n",
        "  print(\"Logging into your LinkedIn account!\")\n",
        "  # Login button\n",
        "  wd.find_element(By.XPATH,'/html/body/main/section[1]/div/div/form/div[2]/button').click()\n",
        "  wd.implicitly_wait(30)\n",
        "  # wd.get_screenshot_as_file('screenshot.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "LYADraZTENqk"
      },
      "outputs": [],
      "source": [
        "def security_verification():\n",
        "  otp = input(\"You have been sent a verification code from LinkedIn via your email.\\nPlease input that here: \")\n",
        "  wd.find_element(By.XPATH, '/html/body/div/main/form/div[1]/input[15]').send_keys(otp)\n",
        "  wd.implicitly_wait(10)\n",
        "  wd.find_element(By.XPATH,'/html/body/div/main/form/div[2]/button').click()\n",
        "  wd.implicitly_wait(30)\n",
        "  # wd.get_screenshot_as_file('screenshot.png')\n",
        "  print(\"Successfully Authenticated!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "2D1XaKWgWF6R"
      },
      "outputs": [],
      "source": [
        "def search_query(query):\n",
        "  # Home page - Clicking on search textfield and sending text\n",
        "  wd.find_element(By.CLASS_NAME, 'search-global-typeahead__typeahead').click()\n",
        "  random_integer = random.randint(3, 7)\n",
        "  time.sleep(random_integer)\n",
        "  wd.find_element(By.CLASS_NAME, 'search-global-typeahead__input').send_keys(query)\n",
        "  random_integer = random.randint(3, 7)\n",
        "  time.sleep(random_integer)\n",
        "  wd.find_element(By.CLASS_NAME, 'search-global-typeahead__input').send_keys(Keys.ENTER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "xtrO1qMO6Ij1"
      },
      "outputs": [],
      "source": [
        "def add_filters(location=None, current_company=None, past_company=None):\n",
        "  # Search Page - Clicking on 'Search People Results' and 'All Filters'\n",
        "\n",
        "  people_results_button = wd.find_element(By.XPATH, \"//*[contains(text(), 'See all people results')]\")\n",
        "  people_page_link = people_results_button.get_attribute(\"href\")\n",
        "  wd.execute_script(\"arguments[0].style.border='2px solid red'\", people_results_button)\n",
        "  wd.get(people_page_link)\n",
        "  wd.implicitly_wait(22)\n",
        "  random_integer = random.randint(0, 2)\n",
        "  time.sleep(random_integer)\n",
        "  # print(\"at people page\")\n",
        "  # wd.get_screenshot_as_file('screenshot_people_page.png')\n",
        "\n",
        "  all_filters = wd.find_element(By.CLASS_NAME, \"relative.mr2\")\n",
        "  wd.execute_script(\"arguments[0].style.border='2px solid red'\", all_filters)\n",
        "  # wd.get_screenshot_as_file('screenshot_all_filters_button.png')\n",
        "  all_filters.click()\n",
        "  # wd.get_screenshot_as_file('screenshot_filters.png')\n",
        "  # print(\"Clicked Filters Button\")\n",
        "  if current_company:\n",
        "  ###########################################\n",
        "    # Adding Current Company Filter\n",
        "    # Filters Page - Scrolling to current company filter\n",
        "    company_filters = wd.find_elements(By.XPATH,\"//*[text()='Add a company']\")\n",
        "    company_filter = company_filters[0]\n",
        "    wd.execute_script(\"arguments[0].scrollIntoView();\", company_filter)\n",
        "    # wd.get_screenshot_as_file('screenshot_company1.png')\n",
        "    # print(\"Found Company Button\")\n",
        "    # wd.implicitly_wait(60)\n",
        "\n",
        "    # Filters Page - Clicking on \"Add a company\"\n",
        "    company_filter.click()\n",
        "    random_integer = random.randint(0, 1)\n",
        "    time.sleep(random_integer)\n",
        "    # print(\"Clicked Company Button\")\n",
        "\n",
        "    # Filters Page - Searching for company\n",
        "    company_input = wd.find_element(By.CSS_SELECTOR, 'input[placeholder=\"Add a company\"]')\n",
        "    # wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_input)\n",
        "    # wd.get_screenshot_as_file('screenshot_company2_1.png')\n",
        "\n",
        "    # random_integer = random.randint(2, 5)\n",
        "    # time.sleep(random_integer)\n",
        "\n",
        "    company_input.click()\n",
        "    # print(\"Clicked company text\")\n",
        "\n",
        "    # random_integer = random.randint(2, 5)\n",
        "    # time.sleep(random_integer)\n",
        "\n",
        "    company_input.send_keys(current_company) #[:int(0.65*len(current_company))]\n",
        "\n",
        "    # random_integer = random.randint(2, 5)\n",
        "    # time.sleep(random_integer)\n",
        "    random_integer = random.randint(1, 2)\n",
        "    # print(\"sent company input text\")\n",
        "    wait = WebDriverWait(wd, random_integer)\n",
        "    listbox = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'basic-typeahead__triggered-content')))\n",
        "    # wd.execute_script(\"arguments[0].style.border='2px solid red'\", listbox)\n",
        "    # wd.get_screenshot_as_file('screenshot_company3.png')\n",
        "    random_integer = random.randint(2, 3)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    options = listbox.find_elements(By.XPATH, \".//div[@role='option']\")\n",
        "\n",
        "    for option in options:\n",
        "      xpath_string = f\".//*[text()='{current_company}']\"\n",
        "      company_option = option.find_element(By.XPATH, xpath_string)\n",
        "      if company_option:\n",
        "        # wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_option)\n",
        "        # wd.get_screenshot_as_file('screenshot_company_dropdown.png')\n",
        "        random_integer = random.randint(0, 1)\n",
        "        time.sleep(random_integer)\n",
        "        company_option.click()\n",
        "        # print(\"clicked on company\")\n",
        "        break\n",
        "\n",
        "  if past_company:\n",
        "    company_filters = wd.find_elements(By.XPATH,\"//*[text()='Add a company']\")\n",
        "    company_filter = company_filters[1]\n",
        "    # company_filter = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div[2]/ul/li[5]')\n",
        "    wd.execute_script(\"arguments[0].scrollIntoView();\", company_filter)\n",
        "    # wd.get_screenshot_as_file('screenshot_company1.png')\n",
        "    # print(\"Found Company Button\")\n",
        "    wd.implicitly_wait(60)\n",
        "\n",
        "    # parent <ul> tag\n",
        "    parent_ul = company_filter.find_element(By.XPATH,\"./ancestor::ul\")\n",
        "    # Filters Page - Clicking on \"Add a company\"\n",
        "    # wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div[2]/ul/li[5]/fieldset/div/ul/li[6]/button').click()\n",
        "    company_filter.click()\n",
        "    # print(\"Clicked Company Button\")\n",
        "    # wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_filter)\n",
        "    wd.implicitly_wait(11)\n",
        "    # wd.get_screenshot_as_file('screenshot_company2.png')\n",
        "    wd.implicitly_wait(70)\n",
        "    clicked = wd.page_source\n",
        "\n",
        "    # Filters Page - Searching for company\n",
        "    # add_company = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div[2]/ul/li[5]/fieldset/div/ul/li[6]/div/div/input')\n",
        "    # add_company.send_keys(company[:int(0.65*len(company))])\n",
        "    company_input = parent_ul.find_element(By.CSS_SELECTOR, 'input[placeholder=\"Add a company\"]')\n",
        "    # print(\"Found company input text\")\n",
        "    wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_input)\n",
        "    # wd.get_screenshot_as_file('screenshot_company2_1.png')\n",
        "    # wd.implicitly_wait(11)\n",
        "    company_input.click()\n",
        "    # print(\"Clicked company text\")\n",
        "    time.sleep(1)\n",
        "    # wd.execute_script(\"arguments[0].value = arguments[1]\", company_input, company[:int(0.65*len(company))])\n",
        "    company_input.send_keys(past_company) #[:int(0.65*len(past_company))]\n",
        "    time.sleep(2)\n",
        "    ember = wd.page_source\n",
        "    # print(\"sent company input text\")\n",
        "    wait = WebDriverWait(wd, 10)\n",
        "    listbox = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'basic-typeahead__triggered-content')))\n",
        "    wd.execute_script(\"arguments[0].style.border='2px solid red'\", listbox)\n",
        "    # wd.get_screenshot_as_file('screenshot_company3.png')\n",
        "    wd.implicitly_wait(30)\n",
        "\n",
        "    # Get all options\n",
        "    options = listbox.find_elements(By.XPATH, \".//div[@role='option']\")\n",
        "\n",
        "    for option in options:\n",
        "      xpath_string = f\".//*[text()='{past_company}']\"\n",
        "      company_option = option.find_element(By.XPATH, xpath_string)\n",
        "      if company_option:\n",
        "        wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_option)\n",
        "        # wd.get_screenshot_as_file('screenshot_company_dropdown.png')\n",
        "        company_option.click()\n",
        "        # print(\"clicked on company\")\n",
        "        break\n",
        "\n",
        "\n",
        "  if location:\n",
        "  ###########################################\n",
        "    # Adding Current Company Filter\n",
        "    # Filters Page - Scrolling to current company filter\n",
        "    location_filter = wd.find_element(By.XPATH,\"//*[text()='Add a location']\")\n",
        "    # company_filter = company_filters[0]\n",
        "    wd.execute_script(\"arguments[0].scrollIntoView();\", location_filter)\n",
        "    # wd.get_screenshot_as_file('screenshot_company1.png')\n",
        "    # print(\"Found location Button\")\n",
        "    wd.implicitly_wait(60)\n",
        "\n",
        "    # Filters Page - Clicking on \"Add a company\"\n",
        "    location_filter.click()\n",
        "    random_integer = random.randint(1, 2)\n",
        "    time.sleep(random_integer)\n",
        "    # print(\"Clicked location Button\")\n",
        "\n",
        "    # Filters Page - Searching for company\n",
        "    location_input = wd.find_element(By.CSS_SELECTOR, 'input[placeholder=\"Add a location\"]')\n",
        "    # wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_input)\n",
        "    # wd.get_screenshot_as_file('screenshot_company2_1.png')\n",
        "\n",
        "    random_integer = random.randint(1, 2)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    location_input.click()\n",
        "    # print(\"Clicked location text\")\n",
        "\n",
        "    random_integer = random.randint(1,2)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    location_input.send_keys(location[:int(0.65*len(location))])\n",
        "\n",
        "    random_integer = random.randint(1, 2)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    # print(\"sent location input text\")\n",
        "    wait = WebDriverWait(wd, 1)\n",
        "    listbox = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'basic-typeahead__triggered-content')))\n",
        "    random_integer = random.randint(0, 1)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    options = listbox.find_elements(By.XPATH, \".//div[@role='option']\")\n",
        "    for option in options:\n",
        "      xpath_string = f\".//*[text()='{location}']\"\n",
        "      location_option = option.find_element(By.XPATH, xpath_string)\n",
        "      if location_option:\n",
        "        random_integer = random.randint(0, 1)\n",
        "        time.sleep(random_integer)\n",
        "        location_option.click()\n",
        "        # print(\"clicked on location\")\n",
        "        break\n",
        "  ###############################################\n",
        "\n",
        "  #############################################\n",
        "  # Filters Page - Clicking on show all results ###Make dynamic\n",
        "  all_results = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div[3]/div/button[2]')\n",
        "  all_results.click()\n",
        "\n",
        "  random_integer = random.randint(1, 2)\n",
        "  time.sleep(random_integer)\n",
        "  # wd.get_screenshot_as_file('screenshot.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "def industry_filter(industry_list_num=0):\n",
        "    all_filters = wd.find_element(By.CLASS_NAME, \"relative.mr2\")\n",
        "    wd.execute_script(\"arguments[0].style.border='2px solid red'\", all_filters)\n",
        "    # wd.get_screenshot_as_file('screenshot_all_filters_button.png')\n",
        "    all_filters.click()\n",
        "\n",
        "    random_integer = random.randint(1, 2)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    industry_filter_ul = wd.find_element(By.XPATH, \"//*[text()='Add an industry']/ancestor::ul[1]\")\n",
        "    wd.execute_script(\"arguments[0].scrollIntoView();\", industry_filter_ul)\n",
        "\n",
        "    li_elements = industry_filter_ul.find_elements(By.TAG_NAME, \"li\")\n",
        "    # Click the 'industry'-th <li> element, noting that list indices are zero-based\n",
        "    if 0 <= industry_list_num < len(li_elements):\n",
        "        li_element = li_elements[industry_list_num]\n",
        "        input_checkbox = li_element.find_element(By.XPATH, \".//input[@type='checkbox']\")\n",
        "        if not input_checkbox.is_selected():\n",
        "            input_checkbox.click()\n",
        "\n",
        "        random_integer = random.randint(1, 2)\n",
        "        time.sleep(random_integer)\n",
        "    else:\n",
        "        print(\"Invalid industry index\")\n",
        "    \n",
        "    all_results = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div[3]/div/button[2]')\n",
        "    all_results.click()\n",
        "\n",
        "    random_integer = random.randint(1, 2)\n",
        "    time.sleep(random_integer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_filters1(location=None, current_company=None, past_company=None):\n",
        "  # Search Page - Clicking on 'Search People Results' and 'All Filters'\n",
        "\n",
        "  people_results_button = wd.find_element(By.XPATH, \"//*[contains(text(), 'See all people results')]\")\n",
        "  people_page_link = people_results_button.get_attribute(\"href\")\n",
        "  wd.execute_script(\"arguments[0].style.border='2px solid red'\", people_results_button)\n",
        "  wd.get(people_page_link)\n",
        "  wd.implicitly_wait(22)\n",
        "  random_integer = random.randint(0, 2)\n",
        "  time.sleep(random_integer)\n",
        "  # print(\"at people page\")\n",
        "  # wd.get_screenshot_as_file('screenshot_people_page.png')\n",
        "\n",
        "  all_filters = wd.find_element(By.CLASS_NAME, \"relative.mr2\")\n",
        "  wd.execute_script(\"arguments[0].style.border='2px solid red'\", all_filters)\n",
        "  # wd.get_screenshot_as_file('screenshot_all_filters_button.png')\n",
        "  all_filters.click()\n",
        "  # wd.get_screenshot_as_file('screenshot_filters.png')\n",
        "  # print(\"Clicked Filters Button\")\n",
        "  if current_company:\n",
        "  ###########################################\n",
        "    # Adding Current Company Filter\n",
        "    # Filters Page - Scrolling to current company filter\n",
        "    company_filters = wd.find_elements(By.XPATH,\"//*[text()='Add a company']\")\n",
        "    company_filter = company_filters[0]\n",
        "    wd.execute_script(\"arguments[0].scrollIntoView();\", company_filter)\n",
        "    # wd.get_screenshot_as_file('screenshot_company1.png')\n",
        "    # print(\"Found Company Button\")\n",
        "    # wd.implicitly_wait(60)\n",
        "\n",
        "    # Filters Page - Clicking on \"Add a company\"\n",
        "    company_filter.click()\n",
        "    random_integer = random.randint(0, 1)\n",
        "    time.sleep(random_integer)\n",
        "    # print(\"Clicked Company Button\")\n",
        "\n",
        "    # Filters Page - Searching for company\n",
        "    company_input = wd.find_element(By.CSS_SELECTOR, 'input[placeholder=\"Add a company\"]')\n",
        "    # wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_input)\n",
        "    # wd.get_screenshot_as_file('screenshot_company2_1.png')\n",
        "\n",
        "    # random_integer = random.randint(2, 5)\n",
        "    # time.sleep(random_integer)\n",
        "\n",
        "    company_input.click()\n",
        "    # print(\"Clicked company text\")\n",
        "\n",
        "    # random_integer = random.randint(2, 5)\n",
        "    # time.sleep(random_integer)\n",
        "\n",
        "    company_input.send_keys(current_company) #[:int(0.65*len(current_company))]\n",
        "\n",
        "    # random_integer = random.randint(2, 5)\n",
        "    # time.sleep(random_integer)\n",
        "    random_integer = random.randint(1, 2)\n",
        "    # print(\"sent company input text\")\n",
        "    wait = WebDriverWait(wd, random_integer)\n",
        "    listbox = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'basic-typeahead__triggered-content')))\n",
        "    # wd.execute_script(\"arguments[0].style.border='2px solid red'\", listbox)\n",
        "    # wd.get_screenshot_as_file('screenshot_company3.png')\n",
        "    random_integer = random.randint(2, 3)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    options = listbox.find_elements(By.XPATH, \".//div[@role='option']\")\n",
        "\n",
        "    for option in options:\n",
        "      xpath_string = f\".//*[text()='{current_company}']\"\n",
        "      company_option = option.find_element(By.XPATH, xpath_string)\n",
        "      if company_option:\n",
        "        # wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_option)\n",
        "        # wd.get_screenshot_as_file('screenshot_company_dropdown.png')\n",
        "        random_integer = random.randint(0, 1)\n",
        "        time.sleep(random_integer)\n",
        "        company_option.click()\n",
        "        # print(\"clicked on company\")\n",
        "        break\n",
        "\n",
        "  if past_company:\n",
        "    company_filters = wd.find_elements(By.XPATH,\"//*[text()='Add a company']\")\n",
        "    company_filter = company_filters[1]\n",
        "    # company_filter = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div[2]/ul/li[5]')\n",
        "    wd.execute_script(\"arguments[0].scrollIntoView();\", company_filter)\n",
        "    # wd.get_screenshot_as_file('screenshot_company1.png')\n",
        "    # print(\"Found Company Button\")\n",
        "    wd.implicitly_wait(60)\n",
        "\n",
        "    # parent <ul> tag\n",
        "    parent_ul = company_filter.find_element(By.XPATH,\"./ancestor::ul\")\n",
        "    # Filters Page - Clicking on \"Add a company\"\n",
        "    # wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div[2]/ul/li[5]/fieldset/div/ul/li[6]/button').click()\n",
        "    company_filter.click()\n",
        "    # print(\"Clicked Company Button\")\n",
        "    # wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_filter)\n",
        "    wd.implicitly_wait(11)\n",
        "    # wd.get_screenshot_as_file('screenshot_company2.png')\n",
        "    wd.implicitly_wait(70)\n",
        "    clicked = wd.page_source\n",
        "\n",
        "    # Filters Page - Searching for company\n",
        "    # add_company = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div[2]/ul/li[5]/fieldset/div/ul/li[6]/div/div/input')\n",
        "    # add_company.send_keys(company[:int(0.65*len(company))])\n",
        "    company_input = parent_ul.find_element(By.CSS_SELECTOR, 'input[placeholder=\"Add a company\"]')\n",
        "    # print(\"Found company input text\")\n",
        "    wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_input)\n",
        "    # wd.get_screenshot_as_file('screenshot_company2_1.png')\n",
        "    # wd.implicitly_wait(11)\n",
        "    company_input.click()\n",
        "    # print(\"Clicked company text\")\n",
        "    time.sleep(1)\n",
        "    # wd.execute_script(\"arguments[0].value = arguments[1]\", company_input, company[:int(0.65*len(company))])\n",
        "    company_input.send_keys(past_company) #[:int(0.65*len(past_company))]\n",
        "    time.sleep(2)\n",
        "    ember = wd.page_source\n",
        "    # print(\"sent company input text\")\n",
        "    wait = WebDriverWait(wd, 10)\n",
        "    listbox = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'basic-typeahead__triggered-content')))\n",
        "    wd.execute_script(\"arguments[0].style.border='2px solid red'\", listbox)\n",
        "    # wd.get_screenshot_as_file('screenshot_company3.png')\n",
        "    wd.implicitly_wait(30)\n",
        "\n",
        "    # Get all options\n",
        "    options = listbox.find_elements(By.XPATH, \".//div[@role='option']\")\n",
        "\n",
        "    for option in options:\n",
        "      xpath_string = f\".//*[text()='{past_company}']\"\n",
        "      company_option = option.find_element(By.XPATH, xpath_string)\n",
        "      if company_option:\n",
        "        wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_option)\n",
        "        # wd.get_screenshot_as_file('screenshot_company_dropdown.png')\n",
        "        company_option.click()\n",
        "        # print(\"clicked on company\")\n",
        "        break\n",
        "\n",
        "\n",
        "  if location:\n",
        "  ###########################################\n",
        "    # Adding Current Company Filter\n",
        "    # Filters Page - Scrolling to current company filter\n",
        "    location_filter = wd.find_element(By.XPATH,\"//*[text()='Add a location']\")\n",
        "    # company_filter = company_filters[0]\n",
        "    wd.execute_script(\"arguments[0].scrollIntoView();\", location_filter)\n",
        "    # wd.get_screenshot_as_file('screenshot_company1.png')\n",
        "    # print(\"Found location Button\")\n",
        "    wd.implicitly_wait(60)\n",
        "\n",
        "    # Filters Page - Clicking on \"Add a company\"\n",
        "    location_filter.click()\n",
        "    random_integer = random.randint(1, 2)\n",
        "    time.sleep(random_integer)\n",
        "    # print(\"Clicked location Button\")\n",
        "\n",
        "    # Filters Page - Searching for company\n",
        "    location_input = wd.find_element(By.CSS_SELECTOR, 'input[placeholder=\"Add a location\"]')\n",
        "    # wd.execute_script(\"arguments[0].style.border='2px solid red'\", company_input)\n",
        "    # wd.get_screenshot_as_file('screenshot_company2_1.png')\n",
        "\n",
        "    random_integer = random.randint(1, 2)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    location_input.click()\n",
        "    # print(\"Clicked location text\")\n",
        "\n",
        "    random_integer = random.randint(1,2)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    location_input.send_keys(location[:int(0.65*len(location))])\n",
        "\n",
        "    random_integer = random.randint(1, 2)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    # print(\"sent location input text\")\n",
        "    wait = WebDriverWait(wd, 1)\n",
        "    listbox = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'basic-typeahead__triggered-content')))\n",
        "    random_integer = random.randint(0, 1)\n",
        "    time.sleep(random_integer)\n",
        "\n",
        "    options = listbox.find_elements(By.XPATH, \".//div[@role='option']\")\n",
        "    for option in options:\n",
        "      xpath_string = f\".//*[text()='{location}']\"\n",
        "      location_option = option.find_element(By.XPATH, xpath_string)\n",
        "      if location_option:\n",
        "        random_integer = random.randint(0, 1)\n",
        "        time.sleep(random_integer)\n",
        "        location_option.click()\n",
        "        # print(\"clicked on location\")\n",
        "        break\n",
        "  ###############################################\n",
        "\n",
        "\n",
        "  #############################################\n",
        "  # Filters Page - Clicking on show all results ###Make dynamic\n",
        "  all_results = wd.find_element(By.XPATH, '/html/body/div[3]/div/div/div[3]/div/button[2]')\n",
        "  all_results.click()\n",
        "\n",
        "  random_integer = random.randint(1, 2)\n",
        "  time.sleep(random_integer)\n",
        "  return wd.current_url\n",
        "  # wd.get_screenshot_as_file('screenshot.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "YfxnIWoNQ1Jg"
      },
      "outputs": [],
      "source": [
        "from selenium.webdriver.wpewebkit.webdriver import WebDriver\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "\n",
        "def collect_links(page_start, limit, unlimited=False):\n",
        "  names = []\n",
        "  curr_jobs = []\n",
        "  summarys = []\n",
        "  locations = []\n",
        "  links = []\n",
        "  while True:\n",
        "    print(f\"Scraping links on Page {page_start}\")\n",
        "    # people_block = wd.find_element(By.CLASS_NAME, \"pv0.ph0.mb2.artdeco-card\")\n",
        "    # people_block = wd.find_element(By.CLASS_NAME, \"reusable-search__entity-result-list.list-style-none\")\n",
        "    people_list = wd.find_elements(By.CLASS_NAME, \"reusable-search__result-container\")\n",
        "    for i,person in enumerate(people_list):\n",
        "      wd.implicitly_wait(1)\n",
        "      try:\n",
        "        wd.execute_script(\"arguments[0].style.border='2px solid red'\", person)\n",
        "        # print(\"box red..now finding links\")\n",
        "        all_links = person.find_elements(By.TAG_NAME ,'a')\n",
        "        name_text = \"\"\n",
        "        curr_job_text = \"\"\n",
        "        link_text = \"\"\n",
        "        summary_text = \"\"\n",
        "        if \"LinkedIn Member\" not in person.text:\n",
        "          name_element = person.find_element(By.CSS_SELECTOR, \".entity-result__title-text.t-16 a span[aria-hidden='true']\")\n",
        "          # names.append(name_element.text)\n",
        "          name_text = name_element.text\n",
        "          print(name_element.text)\n",
        "        else:\n",
        "          # names.append(\"LinkedIn Member\")\n",
        "          name_text = \"LinkedIn Member\"\n",
        "          print(\"LinkedIn Member\")\n",
        "\n",
        "        curr_job = person.find_elements(By.CLASS_NAME, \"entity-result__primary-subtitle.t-14.t-black.t-normal\")\n",
        "\n",
        "        if len(curr_job) > 0:\n",
        "          # curr_jobs.append('\"'+curr_job[0].text+'\"')\n",
        "          curr_job_text = '\"'+curr_job[0].text+'\"'\n",
        "        else:\n",
        "          # curr_jobs.append(\"Null\")\n",
        "          curr_job_text = \"Null\"\n",
        "\n",
        "        p_tags = person.find_elements(By.TAG_NAME ,'p')\n",
        "\n",
        "        if len(p_tags) > 0:\n",
        "          summary = p_tags[0]\n",
        "          #summary = person.find_element(By.CSS_SELECTOR, \".entity-result__summary.entity-result__summary--2-lines.t-12.t-black--light.mb1\")\n",
        "          # summarys.append('\"' + summary.text + '\"')\n",
        "          summary_text = '\"' + summary.text + '\"'\n",
        "        else:\n",
        "          # summarys.append(\"Null\")\n",
        "          summary_text = \"Null\"\n",
        "          # print(summary.text)\n",
        "\n",
        "        location = person.find_element(By.CSS_SELECTOR, \".entity-result__secondary-subtitle.t-14.t-normal\")\n",
        "        # locations.append(location.text)\n",
        "        location_text = location.text\n",
        "\n",
        "        link_added = False\n",
        "        for a in all_links:\n",
        "          if str(a.get_attribute('href')).startswith(\"https://www.linkedin.com/in\") and not str(a.get_attribute('href')).startswith(\"https://www.linkedin.com/in/ACo\") and a.get_attribute('href') not in links:\n",
        "            # links.append(a.get_attribute('href'))\n",
        "            link_text = a.get_attribute('href')\n",
        "            link_added = True\n",
        "            break\n",
        "        \n",
        "        if not link_added:\n",
        "          # links.append(\"Null\")\n",
        "          link_text = \"Null\"\n",
        "        \n",
        "        links.append(link_text)\n",
        "        locations.append(location_text)\n",
        "        summarys.append(summary_text)\n",
        "        names.append(name_text)\n",
        "        curr_jobs.append(curr_job_text)\n",
        "\n",
        "      except NoSuchElementException:\n",
        "        print(\"Required Element Not Found...Moving on\")\n",
        "        wd.execute_script(\"arguments[0].style.border='2px solid green'\", person)\n",
        "        wd.implicitly_wait(5)\n",
        "        continue\n",
        "\n",
        "    random_integer = random.randint(2, 3)\n",
        "    time.sleep(random_integer)\n",
        "    scroll_script = \"window.scrollBy(0, 2000);\"\n",
        "    wd.execute_script(scroll_script)\n",
        "\n",
        "    next_page_button = wd.find_element(By.CLASS_NAME, \"artdeco-pagination__button.artdeco-pagination__button--next\")\n",
        "\n",
        "    if next_page_button.is_enabled():\n",
        "      # wd.get_screenshot_as_file(f'screenshot_page{page_start}.png')\n",
        "      next_page_button.click()\n",
        "      page_start += 1\n",
        "      random_integer = random.randint(1, 2)\n",
        "      time.sleep(random_integer)\n",
        "      # wd.get_screenshot_as_file('screenshot.png')\n",
        "    else:\n",
        "      break\n",
        "\n",
        "    if not unlimited:\n",
        "      if page_start == limit+1:\n",
        "        break\n",
        "\n",
        "  df = pd.DataFrame({\n",
        "    'Name': names,\n",
        "    'Current Job': curr_jobs,\n",
        "    'Relevant Experience to Keyword': summarys,\n",
        "    'Location': locations,\n",
        "    'Profile Link': links\n",
        "  })\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAjNFos-Ekmv"
      },
      "source": [
        "Check screenshot.png after login. If scraper is in homepage, ignore the code chunk below. If scraper is on the **security verification** page, **uncomment and run code below** and continue as usual after."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "oMbJUGZif_tc"
      },
      "outputs": [],
      "source": [
        "from selenium.common.exceptions import NoSuchElementException"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "8FS8B_lIz9k9"
      },
      "outputs": [],
      "source": [
        "def jsonify(about_text, experience_list):\n",
        "  final_dict = {\"About\": about_text, \"Experience\": {}}\n",
        "  for experience in experience_list:\n",
        "      company_dict = {}\n",
        "      if isinstance(experience['job_role'], list) and isinstance(experience['job_time'], list):\n",
        "          for role, time in zip(experience['job_role'], experience['job_time']):\n",
        "              company_dict[role] = time\n",
        "      else:\n",
        "          company_dict[experience['job_role']] = experience['job_time']\n",
        "      # Add the company dictionary to the final dictionary\n",
        "      final_dict[\"Experience\"][experience['company']] = company_dict\n",
        "\n",
        "  # Convert the final dictionary to a JSON string\n",
        "  # json_str = json.dumps(final_dict)\n",
        "  # return json_str\n",
        "  return final_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "def experience_json3(link):\n",
        "  # print(\"Started Time\")\n",
        "  wd.get(link)\n",
        "  about_text = \"\"\n",
        "  wd.implicitly_wait(1)\n",
        "  about_tags = None\n",
        "\n",
        "  try:\n",
        "    about_tags = wd.find_elements(By.XPATH, \"//*[text()='About']\") \n",
        "  except:\n",
        "    wd.implicitly_wait(5)\n",
        "    \n",
        "  if about_tags:\n",
        "    about_tag = about_tags[0]\n",
        "    wd.execute_script(\"arguments[0].scrollIntoView();\", about_tag)\n",
        "    wd.execute_script(\"arguments[0].style.border='2px solid red'\", about_tag)\n",
        "    about_section_tag = about_tag.find_element(By.XPATH, \"ancestor::section\")\n",
        "    wd.execute_script(\"arguments[0].style.border='2px solid blue'\", about_section_tag)\n",
        "\n",
        "    random_integer = random.randint(0, 1)\n",
        "    # print(f\"slept for {random_integer} seconds\")\n",
        "    time.sleep(random_integer)\n",
        "    about_text = about_section_tag.text\n",
        "\n",
        "  scroll_script = \"window.scrollBy(0, 500);\"\n",
        "  wd.execute_script(scroll_script)\n",
        "\n",
        "  # Finding the experience\n",
        "  experience_tag = wd.find_element(By.XPATH, \"//*[text()='Experience']\")\n",
        "  \n",
        "  wd.execute_script(\"arguments[0].scrollIntoView();\", experience_tag)\n",
        "  wd.execute_script(\"arguments[0].style.border='2px solid red'\", experience_tag)\n",
        "  section_tag = experience_tag.find_element(By.XPATH, \"ancestor::section\")\n",
        "  \n",
        "  wd.execute_script(\"arguments[0].style.border='2px solid blue'\", section_tag)\n",
        "\n",
        "  # Isolating the content list\n",
        "  div_tag = section_tag.find_element(By.XPATH, \".//div[@class='pvs-list__outer-container']\")\n",
        "  wd.execute_script(\"arguments[0].style.border='2px solid red'\", div_tag)\n",
        "\n",
        "  experience_list = []\n",
        "  overall_experience = div_tag.find_element(By.XPATH, \".//ul\")\n",
        "\n",
        "  jobs = overall_experience.find_elements(By.XPATH, \"./li\")\n",
        "\n",
        "  random_integer = random.randint(2, 4)\n",
        "\n",
        "  for job in jobs:\n",
        "    company_name = None\n",
        "    \n",
        "    try:\n",
        "      # print(\"Started searching for outer_container\")\n",
        "      wd.implicitly_wait(1) \n",
        "      outer_container = job.find_element(By.CSS_SELECTOR, \"div.pvs-list__outer-container.pvs-entity__sub-components\")\n",
        "      try:\n",
        "        # print(\"Started searching for outer_container2\")\n",
        "        outer_container2 = outer_container.find_element(By.CSS_SELECTOR, \"div.display-flex.flex-wrap.align-items-center.full-height\")\n",
        "        print(\"found outer_container first element\")\n",
        "        company_div_tag = job.find_element(By.CSS_SELECTOR, \"div.display-flex.flex-wrap.align-items-center.full-height\")\n",
        "\n",
        "        wd.execute_script(\"arguments[0].style.border='2px solid yellow'\", company_div_tag)\n",
        "        company_name = company_div_tag.find_element(By.XPATH, \".//span[@aria-hidden='true']\").text\n",
        "\n",
        "        sub_jobs_ul = outer_container.find_element(By.XPATH, \"./ul\")\n",
        "\n",
        "        wd.execute_script(\"arguments[0].style.border='2px solid green'\", sub_jobs_ul)\n",
        "        # Extract the immediate <li> tags within the <ul> tag\n",
        "        sub_jobs = sub_jobs_ul.find_elements(By.XPATH, \"./li\")\n",
        "        sub_job_text = []\n",
        "        sub_job_time = []\n",
        "        for sub_job in sub_jobs:\n",
        "          # Find the div tag with class 'display-flex flex-wrap align-items-center full-height'\n",
        "          div_tag = sub_job.find_element(By.CSS_SELECTOR, \"div.display-flex.flex-wrap.align-items-center.full-height\")\n",
        "\n",
        "          job_role = div_tag.find_element(By.XPATH, \".//span[@aria-hidden='true']\")\n",
        "          sub_job_text.append(job_role.text.split('·')[0].strip())\n",
        "          job_time_outer = sub_job.find_element(By.CSS_SELECTOR, \"span.t-14.t-normal.t-black--light\")\n",
        "          job_time = job_time_outer.find_element(By.XPATH, \".//span[@class='pvs-entity__caption-wrapper']\")\n",
        "          sub_job_time.append(job_time.text.split('·')[0].strip())\n",
        "\n",
        "        company_name = company_name.split('·')[0].strip()\n",
        "        experience_list.append({'company':company_name, 'job_role':sub_job_text, 'job_time':sub_job_time})\n",
        "        continue\n",
        "\n",
        "      except NoSuchElementException:\n",
        "        # print(\"no outer container first element so probably single job\")\n",
        "        wd.implicitly_wait(10)\n",
        "    except NoSuchElementException:\n",
        "      # print(\"no outer container so probably single job\")\n",
        "      wd.implicitly_wait(10)\n",
        "\n",
        "    div_tag = job.find_element(By.CSS_SELECTOR, \"div.display-flex.flex-wrap.align-items-center.full-height\")\n",
        "    wd.execute_script(\"arguments[0].style.border='2px solid yellow'\", div_tag)\n",
        "\n",
        "    job_role = div_tag.find_element(By.XPATH, \".//span[@aria-hidden='true']\").text\n",
        "    job_role = job_role.split('·')[0].strip()\n",
        "\n",
        "    company_outer = job.find_element(By.CSS_SELECTOR, \"span.t-14.t-normal\")\n",
        "    company_name = company_outer.find_element(By.XPATH, \".//span[@aria-hidden='true']\").text\n",
        "    company_name = company_name.split('·')[0].strip()\n",
        "\n",
        "    job_time_outer = job.find_element(By.CSS_SELECTOR, \"span.t-14.t-normal.t-black--light\")\n",
        "    job_time = job_time_outer.find_element(By.XPATH, \".//span[@class='pvs-entity__caption-wrapper']\").text\n",
        "    job_time = job_time.split('·')[0].strip()\n",
        "\n",
        "    experience_list.append({'company':company_name, 'job_role':job_role, 'job_time':job_time})\n",
        "\n",
        "  about_text = about_text.replace(\"About\\nAbout\\n\", \"\", 1)\n",
        "  # print(jsonify(about_text, experience_list))\n",
        "  return jsonify(about_text, experience_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dataframe_output(search_term, location=None, current_company=None, past_company=None, num_pages=4, unlimited=False, industry=True):\n",
        "\n",
        "  search_query(search_term)\n",
        "\n",
        "  print(location)\n",
        "  print(current_company)\n",
        "  print(past_company)\n",
        "  print(num_pages)\n",
        "  \n",
        "  # filters_page = add_filters(location=location, current_company=current_company, past_company=past_company)\n",
        "  filters_page = add_filters1(location=location, current_company=current_company, past_company=past_company)\n",
        "  if industry:\n",
        "    columns = ['Name', 'Current Job', 'Relevant Experience to Keyword', 'Location', 'Profile Link']\n",
        "    df = pd.DataFrame(columns=columns)\n",
        "\n",
        "    industry_options = [2,3,4]\n",
        "    for i in industry_options:\n",
        "      industry_filter(i)\n",
        "      sub_df = collect_links(1,num_pages, unlimited=unlimited)\n",
        "      df = pd.concat([df, sub_df], ignore_index=True)\n",
        "      df.drop_duplicates()\n",
        "      wd.get(filters_page)\n",
        "  else:\n",
        "    df = collect_links(1,num_pages, unlimited=unlimited)\n",
        "    \n",
        "  links = list(df['Profile Link'])\n",
        "  \n",
        "  return df,links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "JCEGHPMn4Kha"
      },
      "outputs": [],
      "source": [
        "def json_data_output(search_term, df, links, location=None, current_company=None, past_company=None, num_pages=4, ):\n",
        "\n",
        "  # search_query(search_term)\n",
        "\n",
        "  # print(location)\n",
        "  # print(current_company)\n",
        "  # print(past_company)\n",
        "  # print(num_pages)\n",
        "  # add_filters(location=location, current_company=current_company, past_company=past_company)\n",
        "\n",
        "  # df = collect_links(1,num_pages)\n",
        "\n",
        "  # links = list(df['Profile Link'])\n",
        "  profile_dicts = []\n",
        "  print(\"Extracting experience into JSON Objects\")\n",
        "  for i, link in enumerate(links):\n",
        "\n",
        "    print(i+1)\n",
        "    if link == \"Null\":\n",
        "      dict = {\"About\":\"Null\", \"Experience\": \"Null\"}\n",
        "      profile_dicts.append(dict)\n",
        "    else:\n",
        "      exp_json = experience_json3(link)\n",
        "      profile_dicts.append(exp_json)\n",
        "\n",
        "  # Creating JSON object per search result\n",
        "  names = list(df['Name'])\n",
        "  curr_jobs = list(df['Current Job'])\n",
        "  locs = list(df['Location'])\n",
        "\n",
        "  profiles = []\n",
        "  for name, curr_job, loc, profile in zip(names, curr_jobs, locs, profile_dicts):\n",
        "\n",
        "    dictionary = {'Name': name, 'Current Job': curr_job[1:-1], 'Location': loc, 'About': profile['About'], 'Experience' : profile['Experience']}\n",
        "    dictionary = json.dumps(dictionary)\n",
        "    profiles.append(dictionary)\n",
        "\n",
        "  # Writing JSON output into file\n",
        "  filename = f\"json_output_{search_term}\"\n",
        "  if current_company:\n",
        "    filename = filename + \"_c-\"+current_company\n",
        "  if past_company:\n",
        "    filename = filename + \"_p-\"+past_company\n",
        "  if location:\n",
        "    filename = filename + \"_l-\"+location\n",
        "\n",
        "  with open(f'{filename}.txt', 'w') as f:\n",
        "    for json_str in profiles:\n",
        "        f.write(json_str + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging into your LinkedIn account!\n"
          ]
        }
      ],
      "source": [
        "login(username, password)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Start Testing Here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "mpNaWK0c-JAv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping your request...\n",
            "('United States', 'Meta', None, 10)\n",
            "United States\n",
            "Meta\n",
            "None\n",
            "10\n",
            "Scraping links on Page 1\n",
            "Travis Nixon\n",
            "Mack Hutsell\n",
            "Baharak S.\n",
            "Hitesh Yalamanchili\n",
            "Keerthi Chidepudi\n",
            "Ashish Shenoy\n",
            "Vinay Hanumaiah\n",
            "Teja Gollapudi\n",
            "Simeng Yang\n",
            "Hyeon Joo\n",
            "Scraping links on Page 2\n",
            "Shaojun Zhang\n",
            "Bekzat Alish\n",
            "Aparajita Saraf\n",
            "Nora Hashemian, Ph.D.\n",
            "Lakshya Kejriwal\n",
            "Pemi N.\n",
            "Cory Nezin\n",
            "Shaojun Luo\n",
            "Ali Fakeri-Tabrizi\n",
            "Reza Sharifi Sedeh\n",
            "Scraping links on Page 3\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[108], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m((location, current_company, past_company, num_pages))\n\u001b[1;32m     38\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 39\u001b[0m df,links \u001b[38;5;241m=\u001b[39m \u001b[43mdataframe_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_term\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_company\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_company\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_company\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_company\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_pages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_pages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(end_time\u001b[38;5;241m-\u001b[39mstart_time)\n",
            "Cell \u001b[0;32mIn[105], line 19\u001b[0m, in \u001b[0;36mdataframe_output\u001b[0;34m(search_term, location, current_company, past_company, num_pages, unlimited, industry)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m industry_options:\n\u001b[1;32m     18\u001b[0m   industry_filter(i)\n\u001b[0;32m---> 19\u001b[0m   sub_df \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_links\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mnum_pages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m   df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, sub_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m   df\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n",
            "Cell \u001b[0;32mIn[101], line 14\u001b[0m, in \u001b[0;36mcollect_links\u001b[0;34m(page_start, limit, unlimited)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping links on Page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# people_block = wd.find_element(By.CLASS_NAME, \"pv0.ph0.mb2.artdeco-card\")\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# people_block = wd.find_element(By.CLASS_NAME, \"reusable-search__entity-result-list.list-style-none\")\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m people_list \u001b[38;5;241m=\u001b[39m \u001b[43mwd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreusable-search__result-container\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i,person \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(people_list):\n\u001b[1;32m     16\u001b[0m   wd\u001b[38;5;241m.\u001b[39mimplicitly_wait(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/Desktop/LinkedInScraping/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:771\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;66;03m# Return empty list if driver returns null\u001b[39;00m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m []\n",
            "File \u001b[0;32m~/Desktop/LinkedInScraping/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    343\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
            "File \u001b[0;32m~/Desktop/LinkedInScraping/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/LinkedInScraping/.venv/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m~/Desktop/LinkedInScraping/.venv/lib/python3.10/site-packages/urllib3/_request_methods.py:144\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    137\u001b[0m         method,\n\u001b[1;32m    138\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/LinkedInScraping/.venv/lib/python3.10/site-packages/urllib3/_request_methods.py:279\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    275\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    277\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/LinkedInScraping/.venv/lib/python3.10/site-packages/urllib3/poolmanager.py:444\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    442\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
            "File \u001b[0;32m~/Desktop/LinkedInScraping/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    790\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    809\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/LinkedInScraping/.venv/lib/python3.10/site-packages/urllib3/connectionpool.py:537\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
            "File \u001b[0;32m~/Desktop/LinkedInScraping/.venv/lib/python3.10/site-packages/urllib3/connection.py:466\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 466\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# login(username, password)\n",
        "\n",
        "current_url = wd.current_url\n",
        "\n",
        "if \"feed\" not in current_url:\n",
        "  security_verification()\n",
        "\n",
        "# query = input(\"What would you like to search? \")\n",
        "\n",
        "# location=None\n",
        "# locYN = input(\"Would you like to add a location filter (Y/N): \")\n",
        "# if locYN == \"Y\":\n",
        "#   location = input(\"Please type in the location you want to filter by: \")\n",
        "\n",
        "\n",
        "# current_company=None\n",
        "# ccYN = input(\"Would you like to add a 'current company' filter (Y/N): \")\n",
        "# if ccYN == \"Y\":\n",
        "#   current_company = input(\"Please type in the company you want to filter by: \")\n",
        "\n",
        "# past_company=None\n",
        "# pcYN = input(\"Would you like to add a 'past company' filter (Y/N): \")\n",
        "# if pcYN == \"Y\":\n",
        "#   past_company = input(\"Please type in the company you want to filter by: \")\n",
        "\n",
        "# num_pages = int(input(\"How many pages of results would you like to scrape? (Enter an integer) \"))\n",
        "\n",
        "query = \"Machine Learning Engineer\"\n",
        "location = \"United States\"\n",
        "current_company = \"Meta\"\n",
        "past_company = None\n",
        "unlimited=False\n",
        "num_pages = 10\n",
        "print(\"Scraping your request...\")\n",
        "\n",
        "print((location, current_company, past_company, num_pages))\n",
        "\n",
        "start_time = time.time()\n",
        "df,links = dataframe_output(search_term=query, location=location, current_company=current_company, past_company=past_company, num_pages=num_pages, unlimited=unlimited)\n",
        "end_time = time.time()\n",
        "print(end_time-start_time)\n",
        "\n",
        "df.to_csv(\"Test.csv\")\n",
        "\n",
        "# ps = json_data_output(search_term=query, location=location, df=df, links=links,current_company=current_company, past_company=past_company, num_pages=num_pages)\n",
        "\n",
        "print(\"Success!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wd.get('https://www.linkedin.com/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if \"feed\" not in current_url:\n",
        "#   security_verification()\n",
        "\n",
        "# query = input(\"What would you like to search? \")\n",
        "\n",
        "# location=None\n",
        "# locYN = input(\"Would you like to add a location filter (Y/N): \")\n",
        "# if locYN == \"Y\":\n",
        "#   location = input(\"Please type in the location you want to filter by: \")\n",
        "\n",
        "\n",
        "# current_company=None\n",
        "# ccYN = input(\"Would you like to add a 'current company' filter (Y/N): \")\n",
        "# if ccYN == \"Y\":\n",
        "#   current_company = input(\"Please type in the company you want to filter by: \")\n",
        "\n",
        "# past_company=None\n",
        "# pcYN = input(\"Would you like to add a 'past company' filter (Y/N): \")\n",
        "# if pcYN == \"Y\":\n",
        "#   past_company = input(\"Please type in the company you want to filter by: \")\n",
        "\n",
        "# num_pages = int(input(\"How many pages of results would you like to scrape? (Enter an integer) \"))\n",
        "\n",
        "# print(\"Scraping your request...\")\n",
        "\n",
        "# print((location, current_company, past_company, num_pages))\n",
        "# ps = json_data_output(search_term=query, location=location, current_company=current_company, past_company=past_company, num_pages=num_pages)\n",
        "\n",
        "# print(\"Success!\")\n",
        "# ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqs0gpb48lox"
      },
      "outputs": [],
      "source": [
        "# login(username, password)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "be8df3a746dc770fc8ec50a8a16d0a923a6575bbbcf271bc91914f68c2488458"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
